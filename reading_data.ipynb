{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2376ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Any, Dict, List, Tuple\n",
    "import matplotlib.pyplot as pt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802b261",
   "metadata": {},
   "source": [
    "### Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcf0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"eng\", \"deu\",\"spa\", \"ita\"] # wspierane języki\n",
    "sentences_by_lang = 200000 # ile zdań bierzemy pod uwagę w poszczególnych językach\n",
    "trigrams_by_lang = 200 # ile trigramów z danego języka bierzemy pod uwagę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2310ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_trigrams(sentence: str):\n",
    "    \"\"\"\n",
    "    Wydobywa trigramy ze zdania.\n",
    "    :param sentence: Zdanie w postaci łańcucha znaków.\n",
    "    :return: Wszystkie trigramy znajdujące się w zdaniu.\n",
    "    \"\"\"\n",
    "    trigrams = []\n",
    "    for i, c in enumerate(sentence):\n",
    "        trigram = sentence[i:(i + 3)]\n",
    "        if len(trigram) == 3:\n",
    "            trigrams.append(trigram)\n",
    "    return trigrams\n",
    "\n",
    "def get_trigrams_sets(df: pd.DataFrame) -> tuple[set, dict]:\n",
    "    \"\"\"\n",
    "    Funkcja dla każdego zdania w tabeli zlicza ilość wystąpień trigramów,\n",
    "    następnie dla każdego języka zwraca  TRIGRAMS_BY_LANG najpopularniejszych trigramów.\n",
    "    Na końcu tworzy zbiór składający się z najpopularniejszych trigramów każdego języka.\n",
    "    :param df: DataFrame zawierająca kolumny \"sentence\" oraz \"lang\"\n",
    "    :return: biór najpopularniejszych trigramów ogólnie, słownik [lang] -> [trigramy w danym języku...]\n",
    "    \"\"\"\n",
    "    all_trigrams: set[str] = set()\n",
    "    lang_trigrams: dict[str, list[tuple[str, int]]] = dict()\n",
    "    for lang in languages:\n",
    "        trigrams = Counter()\n",
    "        series = df[df[\"lang\"] == lang][\"sentence\"]\n",
    "        for sentence in series:\n",
    "            tri = get_trigrams(sentence)\n",
    "            trigrams.update(tri)\n",
    "        trigrams += Counter() # usuwa elemnty z count=0\n",
    "        mc = trigrams.most_common(trigrams_by_lang)\n",
    "        all_trigrams.update([v[0] for v in mc])\n",
    "        lang_trigrams[lang] = mc\n",
    "    return all_trigrams, lang_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e608439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytujemy plik csv tworząc DF z dwoma kolumanmi \"lang\" oraz \"sentence\"\n",
    "csv_file = pd.read_csv('sentences.csv', on_bad_lines='skip', sep='\\t', index_col=0, names=[\"lang\", \"sentence\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c282da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrujemy tabelę, zostawiamy tylko wspierane języki. Dla każdego języka zostawiamy SENTENCES_BY_LANG zdań.\n",
    "dataset = csv_file[csv_file['lang'].isin(languages)]\n",
    "results = pd.DataFrame(columns=[\"lang\",\"sentence\"])\n",
    "for l in languages:\n",
    "    ds = dataset[dataset[\"lang\"] == l].sample(sentences_by_lang)\n",
    "    results = pd.concat([results, ds])\n",
    "results[\"sentence\"] = results[\"sentence\"].str.lower() # pomijamy wielkość liter, aby nie traktować osobno np. \"He\" i \"he\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca01e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trigrams, lang_trigrams = get_trigrams_sets(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d6c292",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a380bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy bag of words, nie wykorzystujemy binarnego bag of words ponieważ trigramy w zdaniu mogą się powtórzyć i stracilibyśmy tę informację.\n",
    "# Wadą BoW jest fakt, że każdy trigram jest tak samo ważny, ale w naszym problemie to nie przeszkadza.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "dic = dict()\n",
    "for i,t in enumerate(all_trigrams):\n",
    "    dic[t]=i\n",
    "vectorizer = CountVectorizer(vocabulary=dic, ngram_range=(3,3), analyzer=\"char\") #ngram_range bierzemy tylko trigramy, analyzer bierzemy pod uwagę znaki,// char_wb nie zliczało poprawnie kolumn\n",
    "train_sentences = results[\"sentence\"]\n",
    "train_langs = results[\"lang\"]\n",
    "X = vectorizer.fit_transform(train_sentences)\n",
    "train_features = pd.DataFrame(data=X.toarray(), columns=all_trigrams)\n",
    "train_min = train_features.min() # najmniejsza wartość z każdej kolumny\n",
    "train_max = train_features.max() # największa wartość z każdej kolumny\n",
    "train_features = (train_features - train_min)/(train_max-train_min) # do poprawy bo zwraca NaN, jeśli max value = 0\n",
    "train_features[\"lang\"] = list(results[\"lang\"]) # dodajemy dodatkową kolumnę z naszym outputem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c5562f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800000x547 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15859081 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ca</th>\n",
       "      <th>las</th>\n",
       "      <th>ehr</th>\n",
       "      <th>on'</th>\n",
       "      <th>go</th>\n",
       "      <th>zio</th>\n",
       "      <th>sei</th>\n",
       "      <th>va</th>\n",
       "      <th>e p</th>\n",
       "      <th>ed</th>\n",
       "      <th>...</th>\n",
       "      <th>ir</th>\n",
       "      <th>che</th>\n",
       "      <th>ha</th>\n",
       "      <th>on</th>\n",
       "      <th>he</th>\n",
       "      <th>qua</th>\n",
       "      <th>hen</th>\n",
       "      <th>i w</th>\n",
       "      <th>sch</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ca  las  ehr  on'  go   zio  sei  va        e p       ed   ...  ir   \\\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.019231  ...  0.0   \n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  ...  0.0   \n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  ...  0.0   \n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.019231  ...  0.0   \n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.019231  ...  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...       ...       ...  ...  ...   \n",
       "799995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.043478  0.000000  ...  0.0   \n",
       "799996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  ...  0.0   \n",
       "799997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  ...  0.0   \n",
       "799998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  ...  0.0   \n",
       "799999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  ...  0.0   \n",
       "\n",
       "        che    ha   on   he  qua       hen  i w  sch  lang  \n",
       "0       0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   eng  \n",
       "1       0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   eng  \n",
       "2       0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   eng  \n",
       "3       0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   eng  \n",
       "4       0.0  0.00  0.0  0.0  0.0  0.083333  0.0  0.0   eng  \n",
       "...     ...   ...  ...  ...  ...       ...  ...  ...   ...  \n",
       "799995  0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   ita  \n",
       "799996  0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   ita  \n",
       "799997  0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   ita  \n",
       "799998  0.0  0.02  0.0  0.0  0.0  0.000000  0.0  0.0   ita  \n",
       "799999  0.0  0.00  0.0  0.0  0.0  0.000000  0.0  0.0   ita  \n",
       "\n",
       "[800000 rows x 548 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9165666    eng\n",
       "6577477    eng\n",
       "6357152    eng\n",
       "4488244    eng\n",
       "6930358    eng\n",
       "          ... \n",
       "7614388    ita\n",
       "5168654    ita\n",
       "1647260    ita\n",
       "2862669    ita\n",
       "4528234    ita\n",
       "Name: lang, Length: 800000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Asercje czy wszystko przebiegło pomyślnie\n",
    "# assert 0 not in train_max\n",
    "# assert 0 not in (train_max-train_min)\n",
    "# assert not train_max.isnull().values.any()\n",
    "# assert not train_min.isnull().values.any()\n",
    "# assert not (train_features - train_min).isnull().values.any()\n",
    "# assert not (train_max-train_min).isnull().values.any()\n",
    "# assert not train_features.isnull().values.any(), train_features.isnull().sum().sum()\n",
    "\n",
    "display(X)\n",
    "display(train_features)\n",
    "display(train_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5607a24",
   "metadata": {},
   "source": [
    "### Przygotowanie modelu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7402d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train_langs, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f7950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#Fit encoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(languages)\n",
    "\n",
    "def encode(y):\n",
    "    \"\"\"\n",
    "    Returns a list of one hot encodings\n",
    "    Params\n",
    "    ---------\n",
    "        y: list of language labels\n",
    "    \"\"\"\n",
    "    \n",
    "    y_encoded = encoder.transform(y)\n",
    "    y_dummy = np_utils.to_categorical(y_encoded)\n",
    "    \n",
    "    return y_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456f16c",
   "metadata": {},
   "source": [
    "### fit -> stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b1af3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "133334/133334 [==============================] - 275s 2ms/step - loss: 0.0491 - accuracy: 0.9822\n",
      "Epoch 2/5\n",
      "133334/133334 [==============================] - 276s 2ms/step - loss: 0.0372 - accuracy: 0.9871\n",
      "Epoch 3/5\n",
      "133334/133334 [==============================] - 274s 2ms/step - loss: 0.0340 - accuracy: 0.9886\n",
      "Epoch 4/5\n",
      "133334/133334 [==============================] - 265s 2ms/step - loss: 0.0329 - accuracy: 0.9892\n",
      "Epoch 5/5\n",
      "133334/133334 [==============================] - 265s 2ms/step - loss: 0.0318 - accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b4e3326430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Get training data\n",
    "x = train_features.drop('lang',axis=1)\n",
    "y = encode(train_features['lang'])\n",
    "#Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=len(x.columns), activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train model\n",
    "model.fit(x, y, epochs=5, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1cbfa",
   "metadata": {},
   "source": [
    "### epoches - number of times you go through the training set\n",
    "### batch_size - size of training set before changing values of variables (accuracy etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d01777f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 8s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "labels=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c7f1bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [encoder.classes_[np.argmax(label)] for label in labels]\n",
    "\n",
    "accuracy_score(y_test,predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}