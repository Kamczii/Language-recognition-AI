{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2376ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import languages, get_trigrams_sets, encode, prepare_dataframe, normalize, \\\n",
    "    FFN_Hyperparams, build_model, create_encoder, test_model, create_feature_dictionary\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802b261",
   "metadata": {},
   "source": [
    "### Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e608439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca01e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trigrams, _ = get_trigrams_sets(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac551b3",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a380bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzymy bag of words, nie wykorzystujemy binarnego bag of words ponieważ trigramy w zdaniu mogą się powtórzyć i stracilibyśmy tę informację.\n",
    "# Wadą BoW jest fakt, że każdy trigram jest tak samo ważny, ale w naszym problemie to nie przeszkadza.\n",
    "dic = create_feature_dictionary(all_trigrams)\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=dic, ngram_range=(3,3), analyzer=\"char\") #ngram_range bierzemy tylko trigramy, analyzer bierzemy pod uwagę znaki,// char_wb nie zliczało poprawnie kolumn\n",
    "with open('count_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "sentences = df[\"sentence\"]\n",
    "langs = df[\"lang\"]\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "# Tworzymy macierz wystąpień poszcególnych trigramów\n",
    "features = pd.DataFrame(data=X.toarray(), columns=all_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b300d7",
   "metadata": {},
   "source": [
    "### Normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58679fd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = normalize(features)\n",
    "features[\"lang\"] = list(langs) # dodajemy dodatkową kolumnę z naszym outputem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6407f",
   "metadata": {},
   "source": [
    "### Podział na dane testowe i treningowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7402d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder()\n",
    "x = features.drop('lang',axis=1)\n",
    "y = encode(features['lang'], encoder)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe03d68",
   "metadata": {},
   "source": [
    "### Przygotowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b1af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = FFN_Hyperparams(len(X_train.columns), len(languages), [500,500,250], 'relu')\n",
    "model = build_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfeacce",
   "metadata": {},
   "source": [
    "### INFO o urządzeniach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016b93ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03e836",
   "metadata": {},
   "source": [
    "### Uruchomienie treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.1201 - accuracy: 0.9579\n",
      "Epoch 2/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.0817 - accuracy: 0.9752\n",
      "Epoch 3/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.0499 - accuracy: 0.9832\n",
      "Epoch 4/30\n",
      "16667/16667 [==============================] - 66s 4ms/step - loss: 0.0428 - accuracy: 0.9879\n",
      "Epoch 5/30\n",
      "16667/16667 [==============================] - 69s 4ms/step - loss: 0.0269 - accuracy: 0.9915\n",
      "Epoch 6/30\n",
      "16667/16667 [==============================] - 68s 4ms/step - loss: 0.0213 - accuracy: 0.9929\n",
      "Epoch 7/30\n",
      "16667/16667 [==============================] - 70s 4ms/step - loss: 0.0178 - accuracy: 0.9940\n",
      "Epoch 8/30\n",
      "16667/16667 [==============================] - 74s 4ms/step - loss: 0.0283 - accuracy: 0.9948\n",
      "Epoch 9/30\n",
      "16667/16667 [==============================] - 69s 4ms/step - loss: 0.0134 - accuracy: 0.9958\n",
      "Epoch 10/30\n",
      "16667/16667 [==============================] - 62s 4ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 11/30\n",
      "16667/16667 [==============================] - 69s 4ms/step - loss: 0.0142 - accuracy: 0.9962\n",
      "Epoch 12/30\n",
      "16667/16667 [==============================] - 71s 4ms/step - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 13/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.0139 - accuracy: 0.9963\n",
      "Epoch 14/30\n",
      "16667/16667 [==============================] - 75s 5ms/step - loss: 0.0127 - accuracy: 0.9969\n",
      "Epoch 15/30\n",
      "16667/16667 [==============================] - 70s 4ms/step - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 16/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 17/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.0113 - accuracy: 0.9973\n",
      "Epoch 18/30\n",
      "16667/16667 [==============================] - 69s 4ms/step - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 19/30\n",
      "16667/16667 [==============================] - 67s 4ms/step - loss: 0.0383 - accuracy: 0.9974\n",
      "Epoch 20/30\n",
      "16667/16667 [==============================] - 75s 5ms/step - loss: 0.0108 - accuracy: 0.9974\n",
      "Epoch 21/30\n",
      "16667/16667 [==============================] - 72s 4ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 22/30\n",
      "16667/16667 [==============================] - 74s 4ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 23/30\n",
      "16667/16667 [==============================] - 75s 4ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      "Epoch 24/30\n",
      "16667/16667 [==============================] - 69s 4ms/step - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 25/30\n",
      "16667/16667 [==============================] - 65s 4ms/step - loss: 0.0115 - accuracy: 0.9977\n",
      "Epoch 26/30\n",
      "16667/16667 [==============================] - 63s 4ms/step - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 27/30\n",
      "16667/16667 [==============================] - 62s 4ms/step - loss: 0.0097 - accuracy: 0.9978\n",
      "Epoch 28/30\n",
      "16667/16667 [==============================] - 68s 4ms/step - loss: 0.0134 - accuracy: 0.9976\n",
      "Epoch 29/30\n",
      "16667/16667 [==============================] - 75s 5ms/step - loss: 0.0088 - accuracy: 0.9978\n",
      "Epoch 30/30\n",
      " 9720/16667 [================>.............] - ETA: 32s - loss: 0.0082 - accuracy: 0.9979"
     ]
    }
   ],
   "source": [
    "# Z użyciem gpu\n",
    "#with tf.device('/GPU:0'):\n",
    "#    model.fit(X_train, y_train, epochs=25, batch_size=6)\n",
    "    \n",
    "# Bez użycia gpu\n",
    "model.fit(x, y, epochs=30, batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ff0cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Test precyzji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test_model(model, encoder, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7f1bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy)\n",
    "if accuracy > 0.8:\n",
    "    model.save(\"trigrams_recognition\")\n",
    "    with open('trigrams_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "    with open('trigrams_count_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964db172",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}